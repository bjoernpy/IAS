{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# increase display width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 2.1\n",
    "## a)\n",
    "\n",
    "   - Erklären der Funktionen:\n",
    "      - fun_true: Berechnet die Funktionswerte der Parabel mit input X\n",
    "      - generateDataSet: Generiert die Datenmatrix X und die Werte T. X-Werte liegen zwischen xmin und xmax, die Werte T werden anschliend mit fun_true berechnet und verzehrt mit sd_noise\n",
    "      - getDataError: Berechnet die least-squares Feher Funktion $ E_d(w) $\n",
    "      - phi_polynomial: gibt $ \\phi(x) $ in abhängigkeit der dimension deg zurück\n",
    "   - Von welcher Funktion sind die Original-Daten $ (x_n , t_n ) $ gesampelt?\n",
    "      - Von fun_true()\n",
    "   - Wie lauten Basisfunktionen $ \\phi_j (x ) $ für j = 1, ...,deg des linearen Modells?\n",
    "      - $ \\phi_0 = 1, \\phi_1 = x, \\phi_2 = x^2, \\phi_3 = x^3, \\phi_4 = x^4, \\phi_5 = x^5 $\n",
    "   - Welche Rolle hat die Variable lmbda?\n",
    "      - lmbda ist der Regularisierungskoeffizient\n",
    "   - Worin unterscheiden sich die Variablen X,T von X_test,T_test?\n",
    "      - X und T sind Trainingsdaten\n",
    "      - X_test und T_test sind Testdaten\n",
    "   - Was stellen im Plot die grünen Kreuze/Punkte, grüne Kurve, rote Kurve dar?\n",
    "      - grüne Kreuze: Lerndaten\n",
    "      - grüne Punkte: Testdaten\n",
    "      - grüne Kurve: ursprüngliche Parabel\n",
    "      - rote Kurve: LSR Regressions Kurve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c)\n",
    " Testen Sie das Programm zunächst ohne Regularisierung (λ = 0) für N = 10:\n",
    "   -  Welche optimalen Gewichte WLSR erhalten Sie für Polynomgrad 5? Wie groß ist der Lern-Datenfehler ED (WLSR )? Wie groß ist der Fehler auf den Testdaten? Warum ist der Test-Daten-Fehler größer als der Lern-Daten-Fehler?\n",
    "      - WLSR: 7.06500519 | -3.86916089 | 1.16066097 | 0.27523414 | 0.23060499 | 0.02613605\n",
    "      - Lerndatenfehler: 151.66995610334055\n",
    "      - Testdatenfehler: 395.93589328572045\n",
    "      - Da mit den das Polynom an die Lern-Daten angepasst ist und dadurch der Fehler geringer ist als mit den nicht angepassten Test-Daten\n",
    "   -  Vergleichen Sie Lern- und Test-Datenfehler für verschiedene Polynomgrade 1, 2, 3,4, 5, 7, 9? Welche Phänomene treten bei zu niedrigem bzw. zu hohem Polynomgrad auf? Warum?\n",
    "      - zu niedrig (1) : Lern- und Testdatenfehler sehr hoch, da die Funktion eine Gerade ist\n",
    "      - zu hoch (ab 7) : Lerndatenfehler sehr niedrig,da die Lerndatenpunkte (fast) genau auf dem Polynom liegen. Testdatenfehler sehr hoch, wegen Overfitting\n",
    "   \n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Polynomgrad</th>\n",
    "      <th>Lerndatenfehler</th>\n",
    "      <th>Testdatenfehler</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>1</td>\n",
    "      <td>1109.2710261079376</td>\n",
    "      <td>2371.9893767560047</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>2</td>\n",
    "      <td>164.25156650010842</td>\n",
    "      <td>215.77040333953397</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>3</td>\n",
    "      <td>163.50151393233</td>\n",
    "      <td>209.67536254495394</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>4</td>\n",
    "      <td>154.6521447284572</td>\n",
    "      <td>374.2566549998215</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>5</td>\n",
    "      <td>151.66995610334055</td>\n",
    "      <td>395.93589328572045</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>7</td>\n",
    "      <td>119.13824260532138</td>\n",
    "      <td>1227.24338382553</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>9</td>\n",
    "      <td>5.080050324384829e-16</td>\n",
    "      <td>37529.47205995081</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "   - Bestimmen Sie das mittlere Gewicht $\\frac{1}{M}\\sum_{j=0}^{M-1} |W_{LSR_j}| $ für verschiedene Polynomgrade 1,2,4,6,9? Warum werden die Gewichte im Mittel größer?\n",
    "      - je höher der Grad der Funktion desto \"kurviger\" kann die Funktion sein. Da die Basisfunktion Quadratischer Natur ist werden für höher Polynomgrade die Gewichte größer\n",
    "      \n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Polynomgrad</th>\n",
    "      <th>mittleres Gewicht</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>1</td>\n",
    "      <td>16.498520760714317</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>2</td>\n",
    "      <td>2.803458967619471</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>4</td>\n",
    "      <td>2.645759485825437</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>6</td>\n",
    "      <td>3.0791985500706756</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>9</td>\n",
    "      <td>33.43074729298795</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "       \n",
    "   - Bestimmen Sie den mittleren Lern- bzw. Test-Datenfehler (pro Datenpunkt) für Polynomgrad 9 und verschiedene Größen des Datensets N = 10, 100, 1000, 10000. Warum wird der eine Fehler kleiner und der andere größer?\n",
    "      - Lerndatenfehler wird größer, da die Funktion sich nur an 9 Punkte genau anpassen kann, jeder zusätzliche Punkt vergrößert den Lerndatenfehler im mittel\n",
    "      - Testdatenfehler wird kleiner, da die Funktion sich immer mehr an die Original-Funktion anpassen kann, dadurch veringern sich die Testdatenfehler\n",
    "      \n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>N</th>\n",
    "      <th>mittlerer Lerndatenfehler</th>\n",
    "      <th>mittlerer Testdatenfehler</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>10</td>\n",
    "      <td>5.080050324384829e-17</td>\n",
    "      <td>3752.947205995081</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>100</td>\n",
    "      <td>43.331059579081</td>\n",
    "      <td>44.07319425691771</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>1000</td>\n",
    "      <td>47.43467339586492</td>\n",
    "      <td>53.18131707204158</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>10000</td>\n",
    "      <td>50.40076433890375</td>\n",
    "      <td>50.423607486606116</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>     \n",
    "      \n",
    "   - Wieviele Daten N braucht man, damit für Polynomgrad 2 die tatsächlichen Koeffizienten der Original-Funktion fun_true bis auf 10% Genauigkeit geschätzt werden können? (ungefährer Wert reicht)\n",
    "      - 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d)\n",
    "Testen Sie das Programm für Polynomgrad 9, N = 10 Daten und Regularisierung $ \\lambda \\ge 0 $:\n",
    "   - Beschreiben Sie kurz (1-2 Sätze) den Nutzen einer Regularisierung?\n",
    "      - Durch die Regularisierung wird die Komplexität der Funktion reduziert und somit versucht Overfitting zu vermeiden\n",
    "   - Bestimmen Sie den Lern- und Test-Datenfehler sowie das mittlere Gewicht für verschiedene Werte $ \\lambda $=0, 0.01, 0.1, 1, 10, 100, 1000, 10000. Welche Probleme treten auf wenn $ \\lambda $ zu klein oder zu groß gewählt wird?\n",
    "      - zu klein (unter 1) : Test-Datenfehler zu groß\n",
    "      - zu groß (ab 100) : Lern- und Test-Datenfehler werden größer, Regularisierung wirkt sich negativ aus \n",
    "      \n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>$ \\lambda $</th>\n",
    "      <th>Lerndatenfehler</th>\n",
    "      <th>Testdatenfehler</th>\n",
    "      <th>mittleres Gewicht</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>0</td>\n",
    "      <td>5.080050324384829e-16</td>\n",
    "      <td>37529.47205995081</td>\n",
    "      <td>33.43074729298795</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>0.01</td>\n",
    "      <td>34.05186926138977</td>\n",
    "      <td>6364.580038520431</td>\n",
    "      <td>14.596340142567367</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>0.1</td>\n",
    "      <td>106.92744496098399</td>\n",
    "      <td>847.6889761063268</td>\n",
    "      <td>3.4180541876253043</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>1</td>\n",
    "      <td>134.61567984433785</td>\n",
    "      <td>368.59677492108955</td>\n",
    "      <td>0.9811605285311635</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>10</td>\n",
    "      <td>158.09431569251805</td>\n",
    "      <td>272.5295877816801</td>\n",
    "      <td>0.4299194408030978</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>100</td>\n",
    "      <td>212.98533792142464</td>\n",
    "      <td>295.1895773286906</td>\n",
    "      <td>0.1035609915177382</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>1000</td>\n",
    "      <td>245.54595466466313</td>\n",
    "      <td>333.2755498358411</td>\n",
    "      <td>0.03382471641597215</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>10000</td>\n",
    "      <td>260.02017931072044</td>\n",
    "      <td>355.2395125237357</td>\n",
    "      <td>0.022525361293376917</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "   - Für welches $ \\lambda $ wird der Generalisierungsfehler (auf den Test-Daten) minimal?\n",
    "      - in unserem Beispiel für $\\lambda=10$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_true(X):                              # compute 1-dim. parable function; X must be Nx1 data matrix\n",
    "    w2,w1,w0 = 3.0,-1.0,2.0                   # true parameters of parable y(x)=w0+w1*x+w2*x*x\n",
    "    return w0+w1*X+w2*np.multiply(X,X)        # return function values (same size as X)\n",
    "\n",
    "def generateDataSet(N,xmin,xmax,sd_noise):    # generate data matrix X and target values T\n",
    "    X=xmin+np.random.rand(N,1)*(xmax-xmin)    # get random x values uniformly in [xmin;xmax)\n",
    "    T=fun_true(X);                            # target values without noise\n",
    "    if(sd_noise>0):\n",
    "        T=T+np.random.normal(0,sd_noise,X.shape) # add noise \n",
    "    return X,T\n",
    "\n",
    "def getDataError(Y,T):                        # compute data error (least squares) between prediction Y and true target values T\n",
    "    D=np.multiply(Y-T,Y-T);                   # squared differences between Y and T\n",
    "    return 0.5*sum(sum(D));                   # return least-squares data error function E_D\n",
    "\n",
    "def phi_polynomial(x,deg=1):                            # compute polynomial basis function vector phi(x) for data x \n",
    "    assert(np.shape(x)==(1,)), \"currently only 1dim data supported\"\n",
    "    return np.array([x[0]**i for i in range(deg+1)]).T; # returns feature vector phi(x)=[1 x x**2 x**3 ... x**deg]\n",
    "\n",
    "def predict(x,W_LSR,deg):\n",
    "    return sum([(x**i)*W_LSR[i] for i in range(deg+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X= [[ 2.71320643]\n",
      " [-4.79248051]\n",
      " [ 1.33648235]\n",
      " [ 2.48803883]\n",
      " [-0.01492988]\n",
      " [-2.75203354]\n",
      " [-3.01937135]\n",
      " [ 2.60530712]\n",
      " [-3.30889163]\n",
      " [-4.11660186]] T= [[24.02637686]\n",
      " [76.78157398]\n",
      " [ 6.06498717]\n",
      " [16.33697066]\n",
      " [ 6.34586048]\n",
      " [39.50347318]\n",
      " [22.71852474]\n",
      " [30.04030926]\n",
      " [40.44148448]\n",
      " [61.40721056]]\n"
     ]
    }
   ],
   "source": [
    "# (I) generate data \n",
    "np.random.seed(10)                            # set seed of random generator (to be able to regenerate data)\n",
    "N=10                                        # number of data samples\n",
    "xmin,xmax=-5.0,5.0                            # x limits\n",
    "sd_noise=10                                   # standard deviation of Guassian noise\n",
    "X,T           = generateDataSet(N, xmin,xmax, sd_noise)             # generate training data\n",
    "X_test,T_test = generateDataSet(N, xmin,xmax, sd_noise)             # generate test data\n",
    "print(\"X=\",X, \"T=\",T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHI= [[ 1.00000000e+00  2.71320643e+00  7.36148915e+00  1.99732397e+01\n",
      "   5.41915225e+01  1.47032787e+02  3.98930304e+02  1.08238027e+03\n",
      "   2.93672111e+03  7.96793059e+03]\n",
      " [ 1.00000000e+00 -4.79248051e+00  2.29678694e+01 -1.10073066e+02\n",
      "   5.27523025e+02 -2.52814381e+03  1.21160799e+04 -5.80660770e+04\n",
      "   2.78280542e+05 -1.33365407e+06]\n",
      " [ 1.00000000e+00  1.33648235e+00  1.78618507e+00  2.38720482e+00\n",
      "   3.19045710e+00  4.26398961e+00  5.69874685e+00  7.61627457e+00\n",
      "   1.01790165e+01  1.36040759e+01]\n",
      " [ 1.00000000e+00  2.48803883e+00  6.19033720e+00  1.54017993e+01\n",
      "   3.83202746e+01  9.53423310e+01  2.37215421e+02  5.90201178e+02\n",
      "   1.46844345e+03  3.65354431e+03]\n",
      " [ 1.00000000e+00 -1.49298770e-02  2.22901226e-04 -3.32788789e-06\n",
      "   4.96849568e-08 -7.41790292e-10  1.10748378e-11 -1.65345966e-13\n",
      "   2.46859493e-15 -3.68558186e-17]\n",
      " [ 1.00000000e+00 -2.75203354e+00  7.57368863e+00 -2.08430452e+01\n",
      "   5.73607595e+01 -1.57858734e+02  4.34432532e+02 -1.19557290e+03\n",
      "   3.29025673e+03 -9.05489689e+03]\n",
      " [ 1.00000000e+00 -3.01937135e+00  9.11660336e+00 -2.75264110e+01\n",
      "   8.31124569e+01 -2.50947371e+02  7.57703304e+02 -2.28778765e+03\n",
      "   6.90768049e+03 -2.08568526e+04]\n",
      " [ 1.00000000e+00  2.60530712e+00  6.78762520e+00  1.76838483e+01\n",
      "   4.60718559e+01  1.20031334e+02  3.12718490e+02  8.14727709e+02\n",
      "   2.12261590e+03  5.53006633e+03]\n",
      " [ 1.00000000e+00 -3.30889163e+00  1.09487638e+01 -3.62282731e+01\n",
      "   1.19875430e+02 -3.96654807e+02  1.31248777e+03 -4.34287981e+03\n",
      "   1.43701187e+04 -4.75491655e+04]\n",
      " [ 1.00000000e+00 -4.11660186e+00  1.69464109e+01 -6.97616264e+01\n",
      "   2.87180841e+02 -1.18220918e+03  4.86668452e+03 -2.00342026e+04\n",
      "   8.24728354e+04 -3.39507828e+05]]\n",
      "W_LSR= [[ 0.00226451]\n",
      " [-0.00132027]\n",
      " [ 0.00743611]\n",
      " [-0.00975257]\n",
      " [ 0.03419477]\n",
      " [-0.03901108]\n",
      " [ 0.10553154]\n",
      " [ 0.01770654]\n",
      " [-0.00682987]\n",
      " [-0.00120636]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programme\\Anacando3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# (II) generate linear least squares model for regression\n",
    "lmbda=10000                                                        # no regression\n",
    "deg=9                                                             # degree of polynomial basis functions\n",
    "N,D = np.shape(X)                                                 # shape of data matrix X\n",
    "N,K = np.shape(T)                                                 # shape of target value matrix T\n",
    "PHI = np.array([phi_polynomial(X[i],deg).T for i in range(N)])    # generate design matrix\n",
    "N,M = np.shape(PHI)                                               # shape of design matrix\n",
    "print(\"PHI=\", PHI)\n",
    "#W_LSR = np.zeros((M,1))                                           # REPLACE THIS BY REGULARIZED LEAST SQUARES WEIGHTS!  \n",
    "#W_LSR = np.linalg.pinv(PHI).dot(T)                  NO REGULIZATION!!!\n",
    "W_LSR = np.linalg.lstsq(PHI.T.dot(PHI) + lmbda * np.identity(N), PHI.T.dot(T))[0]  # this works fine, from : https://stackoverflow.com/questions/27476933/numpy-linear-regression-with-regularization\n",
    "\n",
    "print(\"W_LSR=\",W_LSR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_test= [[3.53688150e-03]\n",
      " [5.00194475e+01]\n",
      " [5.58856554e-01]\n",
      " [2.70770906e+00]\n",
      " [1.75876968e-02]\n",
      " [2.80688624e-02]\n",
      " [2.79129302e-01]\n",
      " [2.20650939e-03]\n",
      " [1.16189199e+00]\n",
      " [1.15596088e-01]]\n",
      "T_test= [[ 3.10905545]\n",
      " [57.97094574]\n",
      " [ 5.36688144]\n",
      " [15.48746047]\n",
      " [ 0.92351025]\n",
      " [-1.52698415]\n",
      " [ 6.31013154]\n",
      " [-2.84101855]\n",
      " [20.36655269]\n",
      " [ 6.00240429]]\n",
      "learn data error =  260.02017931072044\n",
      "test data error =  355.2395125237357\n",
      "W_LSR= [[ 0.00226451]\n",
      " [-0.00132027]\n",
      " [ 0.00743611]\n",
      " [-0.00975257]\n",
      " [ 0.03419477]\n",
      " [-0.03901108]\n",
      " [ 0.10553154]\n",
      " [ 0.01770654]\n",
      " [-0.00682987]\n",
      " [-0.00120636]]\n",
      "mean weight =  0.022525361293376917\n"
     ]
    }
   ],
   "source": [
    "# (III) make predictions for test data\n",
    "#Y_test = np.zeros((N,1))   # REPLACE THIS BY PROGNOSIS FOR TEST DATA X_test! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "Y_test = np.array([predict(x,W_LSR,deg) for x in X_test])\n",
    "#Y_learn = np.zeros((N,1))  # REPLACE THIS BY PROGNOSIS FOR LEARNING DATA X! (result should be N x 1 matrix, i.e., one prognosis per row)\n",
    "Y_learn = np.array([predict(x,W_LSR,deg) for x in X])\n",
    "print(\"Y_test=\",Y_test)\n",
    "print(\"T_test=\",T_test)\n",
    "print(\"learn data error = \", getDataError(Y_learn,T))\n",
    "print(\"test data error = \", getDataError(Y_test,T_test))\n",
    "print(\"W_LSR=\",W_LSR)\n",
    "print(\"mean weight = \", np.mean(np.mean(np.abs(W_LSR))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (IV) plot data\n",
    "ymin,ymax = -50.0,150.0                     # interval of y data\n",
    "x_=np.arange(xmin,xmax,0.01)                # densely sampled x values\n",
    "Y_LSR = np.array([np.dot(W_LSR.T,np.array([phi_polynomial([x],deg)]).T)[0] for x in x_]);   # least squares prediction\n",
    "Y_true = fun_true(x_).flat\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(X.flat,T.flat,c='g',marker='x',s=100)             # plot learning data points (green x)\n",
    "ax.scatter(X_test.flat,T_test.flat,c='g',marker='.',s=100)   # plot test data points (green .)\n",
    "ax.plot(x_,Y_LSR.flat, c='r')         # plot LSR regression curve (red)\n",
    "ax.plot(x_,Y_true, c='g')             # plot true function curve (green)\n",
    "ax.set_xlabel('x')                    # label on x-axis\n",
    "ax.set_ylabel('y')                    # label on y-axis\n",
    "ax.grid()                             # draw a grid\n",
    "plt.ylim((ymin,ymax))                 # set y-limits\n",
    "plt.show()                            # show plot on screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
